# 02.大语言模型架构

### 2.1 Transformer模型

[1.attention](/02.大语言模型架构/1.attention/1.attention.md "1.attention")

[2.layer\_normalization](/02.大语言模型架构/2.layer_normalization/2.layer_normalization.md "2.layer_normalization")

[3.位置编码](/02.大语言模型架构/3.位置编码/3.位置编码.md "3.位置编码")

[4.tokenize分词](/02.大语言模型架构/4.tokenize分词/4.tokenize分词.md "4.tokenize分词")

[5.token及模型参数](/02.大语言模型架构/5.token及模型参数/5.token及模型参数.md "5.token及模型参数")

[6.激活函数](/02.大语言模型架构/6.激活函数/6.激活函数.md "6.激活函数")

### 2.2 注意力

[MHA\_MQA\_GQA](/02.大语言模型架构/MHA_MQA_GQA/MHA_MQA_GQA.md "MHA_MQA_GQA")

### 2.3 解码部分

[解码策略（Top-k & Top-p & Temperature）](</02.大语言模型架构/解码策略（Top-k & Top-p & Temperatu/解码策略（Top-k & Top-p & Temperature）.md> "解码策略（Top-k & Top-p & Temperature）")

### 2.4 BERT

[bert细节](/02.大语言模型架构/bert细节/bert细节.md "bert细节")

[Transformer架构细节](/02.大语言模型架构/Transformer架构细节/Transformer架构细节.md "Transformer架构细节")

[bert变种](/02.大语言模型架构/bert变种/bert变种.md "bert变种")

### 2.5 常见大模型

[llama系列模型](/02.大语言模型架构/llama系列模型/llama系列模型.md "llama系列模型")

[chatglm系列模型](/02.大语言模型架构/chatglm系列模型/chatglm系列模型.md "chatglm系列模型")

[llama 2代码详解](</02.大语言模型架构/llama 2代码详解/llama 2代码详解.md> "llama 2代码详解")

[llama 3](</02.大语言模型架构/llama 3/llama 3.md> "llama 3")

### 2.6 MoE

[1.MoE论文](/02.大语言模型架构/1.MoE论文/1.MoE论文.md "1.MoE论文")

[2.MoE经典论文简牍](/02.大语言模型架构/2.MoE经典论文简牍/2.MoE经典论文简牍.md "2.MoE经典论文简牍")

[3.LLM MoE ：Switch Transformers](</02.大语言模型架构/3.LLM MoE ：Switch Transformers/3.LLM MoE ：Switch Transformers.md> "3.LLM MoE ：Switch Transformers")


